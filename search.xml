<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>0初识爬虫</title>
      <link href="/2022/02/08/0-chu-shi-pa-chong/"/>
      <url>/2022/02/08/0-chu-shi-pa-chong/</url>
      
        <content type="html"><![CDATA[<h1 id="0-认识爬虫"><a href="#0-认识爬虫" class="headerlink" title="0 认识爬虫"></a>0 认识爬虫</h1><p><a href="https://blog.csdn.net/supreme567/article/details/122831465">CSDN链接传送门</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>什么是爬虫？<br>爬虫是什么？<br>了解浏览器的工作原理？<br>爬虫能做很多事，能做商业分析，也能做生活助手，比如：分析北京近两年二手房成交均价是多少？深圳的Python工程师平均薪资是多少？北京哪家餐厅粤菜最好吃？等等。<br>这是个人利用爬虫所做到的事情，而公司，同样可以利用爬虫来实现巨大的商业价值。比如你所熟悉的搜索引擎——百度和谷歌，它们的核心技术之一也是爬虫，而且是超级爬虫。<br>爬虫还让这些搜索巨头有机会朝着人工智能的未来迈进，因为人工智能的发展离不开海量的数据。而每天使用这些搜索网站的用户都是数以亿计的，产生的数据自然也是难以计量的。<br><img src="https://img-blog.csdnimg.cn/2fb29fcae457437f8606931be9f0c8d4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6IOhIOiAgOaWhw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="浏览器的工作原理"></p><p><img src="https://img-blog.csdnimg.cn/b87a5a6fe4fa4481a5523173de2539ad.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6IOhIOiAgOaWhw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>第0步：获取数据。爬虫程序会根据我们提供的网址，向服务器发起请求然后返回数据<br>第1步：解析数据。爬虫程序会把服务器返回的数据解析成我们能读懂的格式。<br>第2步：提取数据。爬虫程序再从中提取出我们需要的数据。<br>第3步：储存数据。爬虫程序把这些有用的数据保存起来，便于你日后的使用和分析。</p><p>requests库可以帮我们下载网页源代码、文本、图片，甚至是音频。其实，“下载”本质上是向服务器发送请求并得到响应。<br>Python是一门面向对象编程的语言，而在爬虫中，理解数据是什么对象是非常、特别、以及极其重要的一件事。因为只有知道了数据是什么对象，我们才知道对象有什么属性和方法可供我们操作。<br><img src="https://img-blog.csdnimg.cn/76ac042c658a44c9b000d1ffdee85db5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6IOhIOiAgOaWhw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/94ca39b8c9fc4e61a4e11ec0ce82be58.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6IOhIOiAgOaWhw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>解析文本为什么会出现一段乱码呢？<br>事情是这样的：首先，目标数据本身有它的编码类型，<br>获取目标数据后要知道相应的编码类型才能正确解码。<br>编解码要共享同一种编码类型，就像你给我传纸条用的编码方式如果是“拼音”，我收到后就要拼“拼音”来理解语意——若我以为是“英语”，去查英语字典，那必然看不懂你说了什么。</p><p>Python关于requests.exceptions.ProxyError异常的问题<br>把VPN关掉就好了</p><p>服务器其实就是一个超级电脑，拥有这个服务器的公司，对爬虫其实也有明确的态度。<br>通常情况下，服务器不太会在意小爬虫，但是，服务器会拒绝频率很高的大型爬虫和恶意爬虫，因为这会给服务器带来极大的压力或伤害。<br>不过，服务器在通常情况下，对搜索引擎是欢迎的态度（刚刚讲过，谷歌和百度的核心技术之一就是爬虫）。当然，这是有条件的，通常这些条件会写在robots协议里。</p><p>robots协议是互联网爬虫的一项公认的道德规范，它的全称是“网络爬虫排除标准”（robots exclusion protocol），这个协议用来告诉爬虫，哪些页面是可以抓取的，哪些不可以。<br>我们使用robots协议的场景通常是：看到想获取的内容后，检查一下网站是否允许爬取。因此我们只需要能找到、简单读懂robots协议就足够了。<br>域名中会藏着网站的国籍或功能领域等信息，那么.cn，.com，.gov结尾的域名分别代表了什么？<br>来看一个实例：我们截取了一部分淘宝的robots协议 （ <a href="http://www.taobao.com/robots.txt%EF%BC%89%E3%80%82%E5%9C%A8%E6%88%AA%E5%8F%96%E7%9A%84%E9%83%A8%E5%88%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%B7%98%E5%AE%9D%E5%AF%B9%E7%99%BE%E5%BA%A6%E5%92%8C%E8%B0%B7%E6%AD%8C%E8%BF%99%E4%B8%A4%E4%B8%AA%E7%88%AC%E8%99%AB%E7%9A%84%E8%AE%BF%E9%97%AE%E8%A7%84%E5%AE%9A%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%AF%B9%E5%85%B6%E5%AE%83%E7%88%AC%E8%99%AB%E7%9A%84%E8%A7%84%E5%AE%9A%E3%80%82">http://www.taobao.com/robots.txt）。在截取的部分，可以看到淘宝对百度和谷歌这两个爬虫的访问规定，以及对其它爬虫的规定。</a></p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">User-agent:  Baiduspiderz # 百度爬虫</span><br><span class="line">Allow:  /article # 允许访问 article </span><br><span class="line">Allow:  /oshtml # 允许访问 oshtml </span><br><span class="line">Allow:  /ershou # 允许访问 ershou </span><br><span class="line">Allow: /$ # 允许访问根目录，即淘宝主页</span><br><span class="line">Disallow:  /product/ # 禁止访问product文件夹下面的所有文件，但是product文件夹本身允许被访问</span><br><span class="line">Disallow:  / # 禁止访问除 Allow 规定页面之外的其他所有页面</span><br><span class="line"></span><br><span class="line">User-Agent:  Googlebot # 谷歌爬虫</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Allow:  /product # 允许访问product文件夹及product文件夹下面的所有文件</span><br><span class="line">Allow:  /spu</span><br><span class="line">Allow:  /dianpu</span><br><span class="line">Allow:  /oversea</span><br><span class="line">Allow:  /list</span><br><span class="line">Allow:  /ershou</span><br><span class="line">Allow: /$</span><br><span class="line">Disallow:  / # 禁止访问除 Allow 规定页面之外的其他所有页面</span><br><span class="line"></span><br><span class="line">…… # 文件太长，省略了对其它爬虫的规定，想看全文的话，点击上面的链接</span><br><span class="line"></span><br><span class="line">User-Agent:  * # 其他爬虫</span><br><span class="line">Disallow:  / # 禁止访问所有页面</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>可以看出robots协议是“分段”的吗？每个段落都含有以下两种字段：一种是User-agent:，另一种是Allow:或Disallow:。<br>User-agent表示的是爬虫类型，上面的示例代码注释了“百度爬虫”和“谷歌爬虫”，我们自己写的爬虫一般要看User-Agent: <em>，</em>指向所有未被明确提及的爬虫。</p><p>Allow代表允许被访问，Disallow代表禁止被访问。字段对应的值都含有路径分隔符/，限制了哪些或哪一层目录的内容是允许或者禁止被访问的。可以对比上述百度爬虫Disallow: /product/和谷歌爬虫Allow: /product的注释行理解一下。<br>比如淘宝禁止其他爬虫访问所有页面，也就是说，我们自己写的爬虫不被欢迎爬取<a href="http://www.taobao.com域名下的任何网页./">www.taobao.com域名下的任何网页。</a><br>有趣的是，淘宝限制了百度对产品页面的爬虫，却允许谷歌访问。</p><p>所以，当你在百度搜索“淘宝网”时，会看到下图的这两行小字。</p><p><img src="https://img-blog.csdnimg.cn/6c805722d9924f498f69f8a3bc6a1785.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6IOhIOiAgOaWhw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>因为百度很好地遵守了淘宝网的robots.txt协议，自然，你在百度中也查不到淘宝网的具体商品信息了。</p><p>互联网并非法外之地，和爬虫相关的法律也在建立和完善之中，目前通用的伦理规范就是robots协议，我们在爬取网络中的信息时，应该有意识地去遵守这个协议。</p><p>网站的服务器被爬虫爬得多了，也会受到较大的压力，因此，各大网站也会做一些反爬虫的措施。不过呢，有反爬虫，也就有相应的反反爬虫</p><p>爬虫就像是核技术，人们可以利用它去做有用的事，也能利用它去搞破坏。</p><p>恶意消耗别人的服务器资源，是一件不道德的事，恶意爬取一些不被允许的数据，还可能会引起严重的法律后果。</p><p>工具在你手中，如何利用它是你的选择。当你在爬取网站数据的时候，别忘了先看看网站的robots协议是否允许你去爬取。</p><p>同时，限制好爬虫的速度，对提供数据的服务器心存感谢，避免给它造成太大压力，维持良好的互联网秩序，也是我们该做的事。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">from requests.<span class="function">exceptions <span class="keyword">import</span> RequestException</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">def <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line"><span class="function">    headers =</span> {<span class="string">"user-agent"</span>: <span class="string">"Mizilla/5.0"</span>}</span><br><span class="line">    response = requests.<span class="built_in">get</span>(url,headers=headers)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"请求成功"</span>)</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line">        elif response.status_code == <span class="number">100</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"继续提出请求"</span>)</span><br><span class="line">            <span class="keyword">return</span> None</span><br><span class="line">        elif response.status_code == <span class="number">305</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"应使用代理访问"</span>)</span><br><span class="line">            <span class="keyword">return</span> None</span><br><span class="line">        elif response.status_code == <span class="number">403</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"禁止访问"</span>)</span><br><span class="line">            <span class="keyword">return</span> None</span><br><span class="line">        elif response.status_code == <span class="number">503</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"服务不可用"</span>)</span><br><span class="line">            <span class="keyword">return</span> None</span><br><span class="line"></span><br><span class="line">    except RequestException:</span><br><span class="line">        <span class="keyword">return</span> None</span><br><span class="line"></span><br><span class="line">def <span class="built_in">main</span>():</span><br><span class="line">    url = <span class="string">'https://localprod.pandateacher.com/python-manuscript/crawler-html/sanguo.md'</span></span><br><span class="line">    html = <span class="built_in">get_one_page</span>(url)</span><br><span class="line">    html.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    novel = html.text</span><br><span class="line">    <span class="built_in">print</span>(novel[:<span class="number">100</span>])</span><br><span class="line">    f = <span class="built_in">open</span>(<span class="string">'《三国演义》.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">    f.<span class="built_in">write</span>(novel)</span><br><span class="line">    f.<span class="built_in">close</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="built_in">main</span>()</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><hr><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://cdn.jsdelivr.net/gh/hyw200199/Figurebed@master/my_image/安智焕21.jpg'</span></span><br><span class="line"></span><br><span class="line">headers = {<span class="string">"user-agent"</span>: <span class="string">"Mizilla/5.0"</span>}</span><br><span class="line">res = requests.<span class="built_in">get</span>(url,headers=headers)</span><br><span class="line">pic = res.content # 把Reponse对象的内容以二进制数据的形式返回</span><br><span class="line"># 新建了一个文件ppt.jpg，这里的文件没加路径，它会被保存在程序运行的当前目录下。</span><br><span class="line"># 图片内容需要以二进制wb读写。你在学习<span class="built_in">open</span>()函数时接触过它。</span><br><span class="line">photo = <span class="built_in">open</span>(<span class="string">'girl1.jpg'</span>,<span class="string">'wb'</span>)</span><br><span class="line"># 获取pic的二进制内容</span><br><span class="line">photo.<span class="built_in">write</span>(pic)</span><br><span class="line"># 关闭文件</span><br><span class="line">photo.<span class="built_in">close</span>()</span><br></pre></td></tr></tbody></table></figure><hr><p><img src="https://img-blog.csdnimg.cn/img_convert/cfa71f586475cf580ec807e5c91c644a.png" alt="that_show"><img src="/0%E5%88%9D%E8%AF%86%E7%88%AC%E8%99%AB/cfa71f586475cf580ec807e5c91c644a.png" alt="that_show"></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> python </tag>
            
            <tag> requests </tag>
            
            <tag> 协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>csoj寒假05</title>
      <link href="/2022/02/07/csoj-han-jia-05/"/>
      <url>/2022/02/07/csoj-han-jia-05/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区间dp </tag>
            
            <tag> 期望dp </tag>
            
            <tag> 树链剖分 </tag>
            
            <tag> 凸包 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cf770_div2题解</title>
      <link href="/2022/02/07/cf770-div2-ti-jie/"/>
      <url>/2022/02/07/cf770-div2-ti-jie/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思维 </tag>
            
            <tag> 构造 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
